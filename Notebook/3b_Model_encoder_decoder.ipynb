{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e28deb4",
   "metadata": {},
   "source": [
    "# UNet Model Encoder Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a0b9c",
   "metadata": {},
   "source": [
    "**Objectif:** le but de ce notebook est d'expliquer la partie Encodeur-Décodeur du modèle UNet.\n",
    "\n",
    "Nous allons voir comment rendre le modèle UNet plus générique en 3 étapes :\n",
    "\n",
    "- 1) ResUNet\n",
    "- 2) Generic  UNet\n",
    "- 3) Generic UNet en séparant Encodeur - Décodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1eb01",
   "metadata": {},
   "source": [
    "### Root Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646ecc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b1ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/ign.fr/ttea/Code_IGN/AerialImageDataset'\n",
    "train_dir = os.path.join(root,'train/images')\n",
    "gt_dir = os.path.join(root,'train/gt')\n",
    "test_dir = os.path.join(root,'test/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f559ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1f888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/ign.fr/ttea/stage_segmentation_2021/Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b817de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.dataloader import InriaDataset\n",
    "from model.model import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f5ed9",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af58ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb58694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var= pd.read_json('variables.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b20f6",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18409b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = (512,512)\n",
    "train_dataset = InriaDataset(var['variables']['root'],tile_size,'train',None,False,1)\n",
    "val_dataset = InriaDataset(var['variables']['root'],tile_size,'validation',None,False,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bce585",
   "metadata": {},
   "source": [
    "## U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d9c6f",
   "metadata": {},
   "source": [
    "![title](../img/Unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112978cf",
   "metadata": {},
   "source": [
    "![title](../img/archi_unet.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92515b",
   "metadata": {},
   "source": [
    "Source de l'architecture du modèle UNet : \n",
    "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206568e6",
   "metadata": {},
   "source": [
    "## UNet - Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9cf4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channel, out_channel):\n",
    "    \"\"\"\n",
    "    in_channel : number of input channel, int \n",
    "    out_channel : number of output channel, int\n",
    "    \n",
    "    Returns : Conv Block of 2x Conv2D with ReLU \n",
    "    \"\"\"\n",
    "    \n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channel, out_channel, kernel_size=3,padding=1),\n",
    "        nn.BatchNorm2d(out_channel),\n",
    "        nn.ReLU(inplace= True),\n",
    "        nn.Conv2d(out_channel, out_channel, kernel_size=3,padding=1),\n",
    "        nn.BatchNorm2d(out_channel),\n",
    "        nn.ReLU(inplace= True),\n",
    "    )\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75da6ab",
   "metadata": {},
   "source": [
    "### Encodeur "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729380b7",
   "metadata": {},
   "source": [
    "La partie Encodeur Block suit l’architecture typique d’un réseau de neurones convolutif. \n",
    "\n",
    "Le réseau consiste en une application répétée de deux convolutions 3x3 chacune suivie d’une ReLU (Rectified Linear Unit) et d’une opération de MaxPooling 2x2 avec une stride de 2 pour le sous-échantillonnage (downsampling). A chaque étape de sous-échantillonnage, on double le nombre de canaux (features channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513d018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,input_channel, output_channel,depth,n_block):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel \n",
    "        self.depth = depth \n",
    "        self.n_block = n_block \n",
    "        \n",
    "        self.conv  = conv_block(self.input_channel, self.output_channel)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        # weight initialization \n",
    "        self.conv[0].apply(self.init_weights)\n",
    "            \n",
    "    def init_weights(self,layer): #gaussian init for the conv layers\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        c = self.conv(x)\n",
    "        if self.depth != self.n_block : \n",
    "            y = self.pool(c)\n",
    "        else : \n",
    "            y = self.conv(x)\n",
    "        \n",
    "        return y,c "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0dd278",
   "metadata": {},
   "source": [
    "### Decodeur "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f11588",
   "metadata": {},
   "source": [
    "Dans la partie du décodeur block, chaque étape consiste en un suréchantillonnage (upsampling) de la carte des caractéristiques suivi d’une convolution 2x2. \n",
    "\n",
    "On va diviser par 2 le nombre de canaux. Puis, s’opère une concatenation avec la carte des caractéristiques rognée par rapport à l’encodeur et d’une opération 3x3 convolutions chacune suivi d’une ReLU. \n",
    "\n",
    "Ensuite, le recadrage est nécessaire en raison de la perte de pixels de bordure dans chaque convolution. Dans notre cas on part du principe que la tuile à une taille de $2^N$ pour qu'on ait pas besoin de recadrer.\n",
    "\n",
    "Au niveau de la couche finale, une opération de convolution 1x1 est utilisée pour mapper chaque vecteur d’entités à 64 composants au nombre de classes souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca41e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,input_channel, output_channel):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel \n",
    "        \n",
    "        self.conv_t  = nn.ConvTranspose2d(self.input_channel,self.output_channel, kernel_size= 2, stride=2)\n",
    "        self.conv = conv_block(self.input_channel,self.output_channel)\n",
    "        \n",
    "        self.conv[0].apply(self.init_weights)\n",
    "            \n",
    "    def init_weights(self,layer): #gaussian init for the conv layers\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "    def forward(self,x,skip):\n",
    "        u = self.conv_t(x)\n",
    "        concat =torch.cat([u,skip],1)\n",
    "        x = self.conv(concat)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70648583",
   "metadata": {},
   "source": [
    "## Unet Base "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b58fc3",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons rendre le modèle UNet plus modulaire en utilisant des blocs pour l'encodeur et le décodeur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03481ffb",
   "metadata": {},
   "source": [
    "### 1) ResUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfce4f5",
   "metadata": {},
   "source": [
    "![title](../img/resunet_archi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e7d12",
   "metadata": {},
   "source": [
    "![title](../img/resunet_archi1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4df2b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic with encoder decoder block \n",
    "class ResUNet(nn.Module):\n",
    "  \"\"\"\n",
    "  UNet network for semantic segmentation\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, n_channels, conv_width,  n_class, n_block, cuda = 1):\n",
    "    \"\"\"\n",
    "    initialization function\n",
    "    n_channels, int, number of input channel\n",
    "    conv_width, int list, depth of the convs\n",
    "    n_class = int,  the number of classes\n",
    "    \"\"\"\n",
    "    super(ResUNet, self).__init__() #necessary for all classes extending the module class\n",
    "    self.is_cuda = cuda\n",
    "    \n",
    "    self.n_class = n_class\n",
    "    self.n_block = n_block \n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    \n",
    "    ## Encoder \n",
    "    \n",
    "    # Conv2D (input channel, outputchannel, kernel size)\n",
    "    \n",
    "    self.enc_1 = EncoderBlock(3,16,1,self.n_block)\n",
    "    self.enc_2 = EncoderBlock(16,32,2,self.n_block)\n",
    "    self.enc_3 = EncoderBlock(32,64,3,self.n_block)\n",
    "    self.enc_4 = EncoderBlock(64,128,4,self.n_block)\n",
    "    self.enc_5 = EncoderBlock(128,256,5,self.n_block)\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "\n",
    "    ## Decoder     \n",
    "    \n",
    "    # Transpose & UpSampling Convblock   \n",
    "    \n",
    "    self.dec_6 = DecoderBlock(256,128)\n",
    "    self.dec_7 = DecoderBlock(128,64)\n",
    "    self.dec_8 = DecoderBlock(64,32)\n",
    "    self.dec_9 = DecoderBlock(32,16)\n",
    "    \n",
    "    # Final Classifyer layer \n",
    "    self.outputs = nn.Conv2d(16, self.n_class, kernel_size= 1)\n",
    "    \n",
    "    \n",
    "    if cuda: #put the model on the GPU memory\n",
    "      self.cuda()\n",
    "    \n",
    "  def init_weights(self,layer): #gaussian init for the conv layers\n",
    "    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "  def forward(self, input):\n",
    "    \"\"\"\n",
    "    the function called to run inference\n",
    "    \"\"\"  \n",
    "    if self.is_cuda: #put data on GPU\n",
    "        input = input.cuda()\n",
    "\n",
    "    # Encoder (Left Side)\n",
    "    enc_1, c1 = self.enc_1(input)\n",
    "    enc_2, c2 = self.enc_2(enc_1)\n",
    "    enc_3, c3 = self.enc_3(enc_2)\n",
    "    enc_4, c4 = self.enc_4(enc_3)\n",
    "    enc_5, c5 = self.enc_5(enc_4) \n",
    "\n",
    "    # Decoder (Right Side)\n",
    "    dec_6 = self.dec_6(c5,c4)\n",
    "    dec_7 = self.dec_7(dec_6,c3)\n",
    "    dec_8 = self.dec_8(dec_7,c2)\n",
    "    dec_9 = self.dec_9(dec_8,c1)\n",
    "    \n",
    "    # Final Output Layer \n",
    "    out = self.outputs(dec_9)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7430a7",
   "metadata": {},
   "source": [
    "### Test ResUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb1a3e",
   "metadata": {},
   "source": [
    "On teste une prédiction sur le dataset de notre modèle UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c521e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred tensor([[[[-0.2899, -2.2368, -3.0741,  ..., -2.5874, -1.0563, -1.0805],\n",
      "          [ 0.0183, -0.9891, -2.5617,  ..., -0.9402, -0.5651, -0.2431],\n",
      "          [ 0.0907, -2.2460, -2.7572,  ..., -1.0026, -1.1300, -0.3771],\n",
      "          ...,\n",
      "          [-1.1415, -1.5136, -1.8253,  ..., -1.1908, -0.8910, -0.2571],\n",
      "          [-0.4873, -1.1744, -1.5253,  ..., -1.5095, -1.5102, -0.2014],\n",
      "          [-1.1275,  0.2517, -0.2992,  ..., -1.2013, -1.2916,  0.4038]],\n",
      "\n",
      "         [[ 0.3558,  0.7494, -0.6236,  ..., -0.4915,  0.2225,  0.1731],\n",
      "          [ 1.7017,  1.7456,  0.3000,  ...,  1.3829,  0.1211,  0.3110],\n",
      "          [ 1.0822,  1.3640, -0.8058,  ...,  0.9789,  1.0568,  0.4268],\n",
      "          ...,\n",
      "          [-0.0248,  0.7234, -0.0905,  ...,  1.5565,  0.0343,  1.3305],\n",
      "          [ 0.3774,  0.6847,  0.1276,  ...,  1.1108,  0.1945,  1.2375],\n",
      "          [ 0.4131,  0.7804,  0.2715,  ...,  0.6444, -0.0973,  0.7394]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "output: torch.Size([1, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "#==================TEST ORIGINAL UNET===============================\n",
    "img, mask = train_dataset[42]\n",
    "resunet = ResUNet(4,[3,16,32,64,128,256,128,64,32,16],2,5)\n",
    "pred = resunet(img[None,:,:,:]) #the None indicate a batch dimension of 4 N,C,W,H\n",
    "print('pred', pred)\n",
    "print('output:',pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a8f09",
   "metadata": {},
   "source": [
    "### 2) Generic UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed691b9",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons rendre le modèle UNet plus générique, on aura le choix sur le nombre de blocs que l'on souhaite mettre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb639d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericUNet(nn.Module):\n",
    "  \"\"\"\n",
    "  UNet network for semantic segmentation\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, n_channels, conv_width,  n_class, n_block, cuda = 1):\n",
    "    \"\"\"\n",
    "    initialization function\n",
    "    n_channels, int, number of input channel\n",
    "    conv_width, int list, depth of the convs\n",
    "    n_class = int,  the number of classes\n",
    "    n_block = int, the number of blocks \n",
    "    \"\"\"\n",
    "    super(GenericUNet, self).__init__() #necessary for all classes extending the module class\n",
    "    self.is_cuda = cuda\n",
    "    \n",
    "    self.n_class = n_class\n",
    "    self.n_block = n_block \n",
    "    self.conv_width = conv_width \n",
    "    \n",
    "    self.enc = []\n",
    "    self.dec = []\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    \n",
    "    ## Encoder \n",
    "    \n",
    "    # Conv2D (input channel, outputchannel, kernel size)\n",
    "    \n",
    "    for i in range(self.n_block):\n",
    "        self.enc.append(EncoderBlock(self.conv_width[i],self.conv_width[i+1],i+1,self.n_block))\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "\n",
    "    self.enc = nn.ModuleList(self.enc)\n",
    "    \n",
    "    ## Decoder     \n",
    "    \n",
    "    # Transpose & UpSampling Convblock   \n",
    "    \n",
    "    for i in range(self.n_block-1):\n",
    "        self.dec.append(DecoderBlock(self.conv_width[self.n_block+i],self.conv_width[self.n_block+i+1]))\n",
    "    \n",
    "    self.dec = nn.ModuleList(self.dec)\n",
    "    \n",
    "    # Final Classifyer layer \n",
    "    \n",
    "    self.outputs = nn.Conv2d(self.conv_width[-1], self.n_class, kernel_size= 1)\n",
    "    \n",
    "    if cuda: #put the model on the GPU memory\n",
    "      self.cuda()\n",
    "    \n",
    "  def init_weights(self,layer): #gaussian init for the conv layers\n",
    "    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "  def forward(self, input):\n",
    "    \"\"\"\n",
    "    the function called to run inference\n",
    "    \"\"\"  \n",
    "    if self.is_cuda: #put data on GPU\n",
    "        input = input.cuda()\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # Encoder (Left Side)\n",
    "    \n",
    "    enc = []\n",
    "    skip = [] \n",
    "    \n",
    "    for i in range(self.n_block):\n",
    "        \n",
    "        if i == 0:\n",
    "            enc.append(self.enc[i](input)[0])\n",
    "            skip.append(self.enc[i](input)[1])\n",
    "            \n",
    "        else : \n",
    "            enc.append(self.enc[i](enc[i-1])[0])\n",
    "            skip.append(self.enc[i](enc[i-1])[1])\n",
    "        \n",
    "    #--------------------------------------------------\n",
    "    # Decoder (Right Side)\n",
    "    \n",
    "    dec = []\n",
    "    \n",
    "    for i in range(self.n_block-1):\n",
    "        if i==0:\n",
    "            dec.append(self.dec[i](skip[self.n_block -1 -i],skip[self.n_block -2 -i]))\n",
    "            \n",
    "        else :\n",
    "            dec.append(self.dec[i](dec[i-1],skip[self.n_block -2 -i]))\n",
    "            \n",
    "    # Final Output Layer \n",
    "    out = self.outputs(dec[-1])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42df35",
   "metadata": {},
   "source": [
    "### Test Generic UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18ac3e",
   "metadata": {},
   "source": [
    "On teste le modèle UNet plus générique avec 6 blocs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b5c15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred tensor([[[[-0.2131,  0.5633,  0.2117,  ..., -1.6208, -0.9975, -1.4223],\n",
      "          [-1.3358, -2.3274, -3.7664,  ..., -3.3160, -2.6979, -1.4786],\n",
      "          [-0.2512, -0.5876, -0.8398,  ..., -0.3336, -0.8518, -0.9039],\n",
      "          ...,\n",
      "          [-0.7367, -0.3769,  0.1643,  ..., -0.3110, -0.5660, -1.0184],\n",
      "          [-0.7237, -0.2038, -0.7381,  ..., -0.5771, -0.8188, -0.5405],\n",
      "          [-0.1703,  0.3448,  0.1999,  ..., -0.0998, -0.6215, -0.2605]],\n",
      "\n",
      "         [[-0.3502, -1.1615, -2.4874,  ..., -2.0258,  0.0356, -0.5310],\n",
      "          [-1.3203, -2.0100, -3.2108,  ..., -2.7610, -2.0505, -0.9934],\n",
      "          [ 0.3092, -0.4771,  0.8538,  ...,  0.2275,  0.4106, -0.4113],\n",
      "          ...,\n",
      "          [ 0.0856,  0.6214, -0.6505,  ..., -1.2896,  1.2099, -0.3725],\n",
      "          [-0.1630,  0.3134, -0.3557,  ..., -0.3791,  0.3965, -0.1680],\n",
      "          [ 1.4410,  0.9095,  0.5545,  ...,  0.2636,  0.4518, -0.0874]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "output: torch.Size([1, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "img, mask = train_dataset[42]\n",
    "unet = GenericUNet(4,[3,16,32,64,128,256,512,256,128,64,32,16],2,6)\n",
    "pred = unet(img[None,:,:,:]) #the None indicate a batch dimension of 4 N,C,W,H\n",
    "print('pred', pred)\n",
    "print('output:',pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f7a57",
   "metadata": {},
   "source": [
    "### 3) Generic UNet en séparant Encodeur - Décodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eed85b",
   "metadata": {},
   "source": [
    "Dans cette dernière partie, on sépare en 2 classes l'encodeur et le décodeur du modèle UNet générique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbbbee5",
   "metadata": {},
   "source": [
    "### Encodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "104f7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericUNetEncoder(nn.Module):\n",
    "  \"\"\"\n",
    "  UNet network for semantic segmentation\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, n_channels, conv_width,  n_class, n_block, cuda = 1):\n",
    "    \"\"\"\n",
    "    initialization function\n",
    "    n_channels, int, number of input channel\n",
    "    conv_width, int list, depth of the convs\n",
    "    n_class = int,  the number of classes\n",
    "    n_block = int, the number of blocks \n",
    "    \"\"\"\n",
    "    super(GenericUNetEncoder, self).__init__() #necessary for all classes extending the module class\n",
    "    self.is_cuda = cuda\n",
    "    \n",
    "    self.n_class = n_class\n",
    "    self.n_block = n_block \n",
    "    self.conv_width = conv_width \n",
    "    \n",
    "    self.enc = []\n",
    "    \n",
    "    # Conv2D (input channel, outputchannel, kernel size)\n",
    "    \n",
    "    for i in range(self.n_block):\n",
    "        self.enc.append(EncoderBlock(self.conv_width[i],self.conv_width[i+1],i+1,self.n_block))\n",
    "    \n",
    "    self.enc = nn.ModuleList(self.enc)\n",
    "    \n",
    "    if cuda: #put the model on the GPU memory\n",
    "      self.cuda()\n",
    "    \n",
    "  def init_weights(self,layer): #gaussian init for the conv layers\n",
    "    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "  def forward(self, input):\n",
    "    \"\"\"\n",
    "    the function called to run inference\n",
    "    \"\"\"  \n",
    "    if self.is_cuda: #put data on GPU\n",
    "        input = input.cuda()\n",
    "    \n",
    "    enc = []\n",
    "    skip = [] \n",
    "    \n",
    "    for i in range(self.n_block):\n",
    "        \n",
    "        if i == 0:\n",
    "            enc.append(self.enc[i](input)[0])\n",
    "            skip.append(self.enc[i](input)[1])\n",
    "            \n",
    "        else : \n",
    "            enc.append(self.enc[i](enc[i-1])[0])\n",
    "            skip.append(self.enc[i](enc[i-1])[1])\n",
    "    \n",
    "    return enc, skip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe7433",
   "metadata": {},
   "source": [
    "### Décodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e054a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericUNetDecoder(nn.Module):\n",
    "  \"\"\"\n",
    "  UNet network for semantic segmentation\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, n_channels, conv_width,  n_class, n_block,encoder, cuda = 1):\n",
    "    \"\"\"\n",
    "    initialization function\n",
    "    n_channels, int, number of input channel\n",
    "    conv_width, int list, depth of the convs\n",
    "    n_class = int,  the number of classes\n",
    "    n_block = int, the number of blocks \n",
    "    \"\"\"\n",
    "    super(GenericUNetDecoder, self).__init__() #necessary for all classes extending the module class\n",
    "    self.is_cuda = cuda\n",
    "    \n",
    "    self.n_class = n_class\n",
    "    self.n_block = n_block \n",
    "    self.conv_width = conv_width \n",
    "    \n",
    "    self.skip = encoder[1]\n",
    "    self.dec= []\n",
    "    \n",
    "    ## Decoder     \n",
    "    \n",
    "    # Transpose & UpSampling Convblock   \n",
    "    for i in range(self.n_block-1):\n",
    "        self.dec.append(DecoderBlock(self.conv_width[self.n_block+i],self.conv_width[self.n_block+i+1]))\n",
    "    \n",
    "    self.dec = nn.ModuleList(self.dec)\n",
    "    \n",
    "    # Final Classifyer layer \n",
    "    \n",
    "    self.outputs = nn.Conv2d(self.conv_width[-1], self.n_class, kernel_size= 1)\n",
    "    \n",
    "    if cuda: #put the model on the GPU memory\n",
    "      self.cuda()\n",
    "    \n",
    "  def init_weights(self,layer): #gaussian init for the conv layers\n",
    "    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "  def forward(self, input):\n",
    "    \"\"\"\n",
    "    the function called to run inference\n",
    "    \"\"\"  \n",
    "    \n",
    "    dec = []\n",
    "    \n",
    "    for i in range(self.n_block-1):\n",
    "        if i==0:\n",
    "            dec.append(self.dec[i](self.skip[self.n_block -1 -i],self.skip[self.n_block -2 -i]))\n",
    "        else :\n",
    "            dec.append(self.dec[i](dec[i-1],self.skip[self.n_block -2 -i]))\n",
    "            \n",
    "    # Final Output Layer \n",
    "    out = self.outputs(dec[-1])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588030b",
   "metadata": {},
   "source": [
    "### Generic UNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "709f617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericUNetClass(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet network for semantic segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels, conv_width,  n_class, n_block,encoder, decoder,cuda = 1):\n",
    "        \"\"\"\n",
    "        initialization function\n",
    "        n_channels, int, number of input channel\n",
    "        conv_width, int list, depth of the convs\n",
    "        n_class = int,  the number of classes\n",
    "        n_block = int, the number of blocks \n",
    "        \"\"\"\n",
    "        super(GenericUNetClass, self).__init__() #necessary for all classes extending the module class\n",
    "        self.is_cuda = cuda\n",
    "\n",
    "        self.n_class = n_class\n",
    "        self.n_block = n_block \n",
    "        self.conv_width = conv_width \n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def init_weights(self,layer): #gaussian init for the conv layers\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        the function called to run inference\n",
    "        \"\"\"  \n",
    "\n",
    "        pred_encoder = self.encoder(input)\n",
    "        decoder = self.decoder \n",
    "        pred = decoder(pred_encoder)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6816ce",
   "metadata": {},
   "source": [
    "### Test Generic UNet en séparant Encodeur - Décodeur "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6240fc",
   "metadata": {},
   "source": [
    "On teste le modèle UNet générique avec l'encodeur & décodeur séparer en 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3001569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred tensor([[[[-0.0860,  0.1551, -1.2594,  ..., -0.1608, -0.0376,  0.0151],\n",
      "          [ 0.8313,  0.9004, -1.3940,  ..., -1.3096, -0.5543, -0.8411],\n",
      "          [-0.7892, -1.1880, -2.2894,  ..., -0.0720, -1.0506, -0.1327],\n",
      "          ...,\n",
      "          [-0.2811, -0.1471,  0.4162,  ..., -0.3011, -0.1364, -0.5183],\n",
      "          [-1.1043, -1.5766, -1.1670,  ..., -2.0284, -2.0353, -0.4065],\n",
      "          [ 0.3011, -0.5562,  0.2887,  ...,  0.1611,  0.8592, -0.1770]],\n",
      "\n",
      "         [[-0.2717,  0.5485, -0.0673,  ...,  0.6280,  0.5707,  0.3428],\n",
      "          [ 1.2669,  1.0678,  1.3669,  ...,  1.8978, -0.9913, -0.1743],\n",
      "          [ 0.7372, -0.0643, -0.4601,  ...,  0.7972, -0.1540, -0.6832],\n",
      "          ...,\n",
      "          [ 0.0423,  1.5815, -0.4739,  ...,  2.5910,  1.3197, -0.0674],\n",
      "          [ 0.5232,  0.8467, -0.4205,  ...,  0.0447,  0.9199,  0.0938],\n",
      "          [ 1.5002, -0.0296,  0.6641,  ...,  1.2951,  0.9067,  1.1532]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "output: torch.Size([1, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "img, mask = train_dataset[42]\n",
    "encoder =  GenericUNetEncoder(4,[3,16,32,64,128,256,128,64,32,16],2,5)\n",
    "pred_encoder = encoder(img[None,:,:,:]) \n",
    "\n",
    "decoder =  GenericUNetDecoder(4,[3,16,32,64,128,256,128,64,32,16],2,5,pred_encoder)\n",
    "\n",
    "generic_unet = GenericUNetClass(4,[3,16,32,64,128,256,128,64,32,16],2,5,encoder,decoder)\n",
    "pred = generic_unet(img[None,:,:,:])\n",
    "\n",
    "print('pred', pred)\n",
    "print('output:',pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
